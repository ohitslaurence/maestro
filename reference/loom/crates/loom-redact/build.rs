// Copyright (c) 2025 Geoffrey Huntley <ghuntley@ghuntley.com>. All rights reserved.
// SPDX-License-Identifier: Proprietary

use serde::Deserialize;
use std::env;
use std::fs;
use std::io::Write;
use std::path::Path;

#[derive(Debug, Deserialize)]
struct GitleaksConfig {
	#[serde(default)]
	rules: Vec<Rule>,
	#[allow(dead_code)]
	#[serde(default)]
	allowlist: Option<GlobalAllowlist>,
}

#[allow(dead_code)]
#[derive(Debug, Deserialize)]
struct GlobalAllowlist {
	#[serde(default)]
	regexes: Vec<String>,
	#[serde(default)]
	stopwords: Vec<String>,
	#[serde(default)]
	paths: Vec<String>,
}

#[derive(Debug, Deserialize)]
struct Rule {
	id: String,
	#[allow(dead_code)]
	#[serde(default)]
	description: String,
	#[serde(default)]
	regex: Option<String>,
	#[allow(dead_code)]
	#[serde(default)]
	path: Option<String>,
	#[serde(default)]
	entropy: Option<f32>,
	#[serde(rename = "secretGroup", default)]
	secret_group: Option<u32>,
	#[serde(default)]
	keywords: Vec<String>,
	#[serde(default)]
	allowlists: Vec<Allowlist>,
}

#[derive(Debug, Deserialize)]
struct Allowlist {
	#[serde(default)]
	regexes: Vec<String>,
	#[serde(default)]
	stopwords: Vec<String>,
	#[allow(dead_code)]
	#[serde(rename = "regexTarget", default)]
	regex_target: Option<String>,
	#[allow(dead_code)]
	#[serde(default)]
	description: Option<String>,
	#[allow(dead_code)]
	#[serde(default)]
	condition: Option<String>,
	#[allow(dead_code)]
	#[serde(default)]
	paths: Vec<String>,
}

fn has_unsupported_regex_features(pattern: &str) -> bool {
	pattern.contains("(?=")
		|| pattern.contains("(?!")
		|| pattern.contains("(?<=")
		|| pattern.contains("(?<!")
}

fn escape_literal_braces(pattern: &str) -> String {
	use regex::Regex;

	lazy_static::lazy_static! {
		static ref QUANTIFIER: Regex = Regex::new(r"\{(\d+(?:,\d*)?)\}").unwrap();
	}

	let mut result = String::with_capacity(pattern.len() + 32);
	let chars: Vec<char> = pattern.chars().collect();
	let mut i = 0;

	while i < chars.len() {
		let c = chars[i];

		if c == '\\' && i + 1 < chars.len() {
			result.push(c);
			result.push(chars[i + 1]);
			i += 2;
			continue;
		}

		if c == '{' {
			let rest: String = chars[i..].iter().collect();
			if let Some(m) = QUANTIFIER.find(&rest) {
				if m.start() == 0 {
					result.push_str(m.as_str());
					i += m.end();
					continue;
				}
			}
			result.push_str("\\{");
		} else if c == '}' {
			result.push_str("\\}");
		} else {
			result.push(c);
		}
		i += 1;
	}
	result
}

fn validate_regex(pattern: &str) -> Result<String, regex::Error> {
	let escaped = escape_literal_braces(pattern);
	regex::RegexBuilder::new(&escaped)
		.size_limit(50 * 1024 * 1024) // 50MB limit for large patterns
		.build()
		.map(|_| escaped)
}

fn main() {
	let manifest_dir = env::var("CARGO_MANIFEST_DIR").expect("CARGO_MANIFEST_DIR not set");
	let toml_path = Path::new(&manifest_dir).join("third_party/gitleaks/gitleaks.toml");
	println!("cargo:rerun-if-changed={}", toml_path.display());

	let toml_content = fs::read_to_string(&toml_path).expect("Failed to read gitleaks.toml");

	let config: GitleaksConfig =
		toml::from_str(&toml_content).expect("Failed to parse gitleaks.toml");

	let out_dir = env::var("OUT_DIR").expect("OUT_DIR not set");
	let out_path = Path::new(&out_dir).join("generated_rules.rs");
	let mut file = fs::File::create(&out_path).expect("Failed to create generated_rules.rs");

	writeln!(
		file,
		"// Copyright (c) 2025 Geoffrey Huntley <ghuntley@ghuntley.com>. All rights reserved.
// SPDX-License-Identifier: Proprietary
// This file is auto-generated by build.rs. Do not edit manually.

pub struct GeneratedRule {{
\tpub id: &'static str,
\tpub regex: &'static str,
\tpub secret_group: u32,
\tpub entropy: Option<f32>,
\tpub keywords: &'static [&'static str],
\tpub allowlist_patterns: &'static [&'static str],
\tpub allowlist_stopwords: &'static [&'static str],
}}

pub static GENERATED_RULES: &[GeneratedRule] = &["
	)
	.unwrap();

	let mut total_rules = 0;
	let mut skipped_rules = 0;
	let mut generated_rules = 0;

	for rule in &config.rules {
		total_rules += 1;

		let regex = match &rule.regex {
			Some(r) => r,
			None => {
				println!(
					"cargo:warning=Skipping rule '{}': no regex pattern (path-only rule)",
					rule.id
				);
				skipped_rules += 1;
				continue;
			}
		};

		if has_unsupported_regex_features(regex) {
			println!(
				"cargo:warning=Skipping rule '{}': regex contains lookahead/lookbehind",
				rule.id
			);
			skipped_rules += 1;
			continue;
		}

		let escaped_regex = match validate_regex(regex) {
			Ok(r) => r,
			Err(e) => {
				println!(
					"cargo:warning=Skipping rule '{}': invalid regex: {}",
					rule.id, e
				);
				skipped_rules += 1;
				continue;
			}
		};

		let mut all_allowlist_patterns: Vec<String> = Vec::new();
		let mut all_allowlist_stopwords: Vec<String> = Vec::new();
		let mut skip_rule = false;

		for allowlist in &rule.allowlists {
			for pattern in &allowlist.regexes {
				if has_unsupported_regex_features(pattern) {
					println!(
						"cargo:warning=Skipping rule '{}': allowlist regex contains lookahead/lookbehind",
						rule.id
					);
					skip_rule = true;
					break;
				}
				match validate_regex(pattern) {
					Ok(escaped) => {
						all_allowlist_patterns.push(escaped);
					}
					Err(e) => {
						let err_msg = e.to_string().replace('\n', " ");
						println!(
							"cargo:warning=Skipping rule '{}': invalid allowlist regex: {} (pattern: {}...)",
							rule.id,
							err_msg,
							&pattern[..pattern.len().min(50)]
						);
						skip_rule = true;
						break;
					}
				}
			}
			if skip_rule {
				break;
			}
			all_allowlist_stopwords.extend(allowlist.stopwords.clone());
		}

		if skip_rule {
			skipped_rules += 1;
			continue;
		}

		let secret_group = rule.secret_group.unwrap_or(0);

		let entropy_str = match rule.entropy {
			Some(e) => format!("Some({:.1}_f32)", e),
			None => "None".to_string(),
		};

		let keywords_str = if rule.keywords.is_empty() {
			"&[]".to_string()
		} else {
			format!(
				"&[{}]",
				rule
					.keywords
					.iter()
					.map(|k| format!("r#\"{}\"#", k))
					.collect::<Vec<_>>()
					.join(", ")
			)
		};

		let allowlist_patterns_str = if all_allowlist_patterns.is_empty() {
			"&[]".to_string()
		} else {
			format!(
				"&[{}]",
				all_allowlist_patterns
					.iter()
					.map(|p| format!("r#\"{}\"#", p))
					.collect::<Vec<_>>()
					.join(", ")
			)
		};

		let allowlist_stopwords_str = if all_allowlist_stopwords.is_empty() {
			"&[]".to_string()
		} else {
			format!(
				"&[{}]",
				all_allowlist_stopwords
					.iter()
					.map(|s| format!("r#\"{}\"#", s))
					.collect::<Vec<_>>()
					.join(", ")
			)
		};

		writeln!(
			file,
			"\tGeneratedRule {{
\t\tid: r#\"{}\"#,
\t\tregex: r#\"{}\"#,
\t\tsecret_group: {},
\t\tentropy: {},
\t\tkeywords: {},
\t\tallowlist_patterns: {},
\t\tallowlist_stopwords: {},
\t}},",
			rule.id,
			escaped_regex,
			secret_group,
			entropy_str,
			keywords_str,
			allowlist_patterns_str,
			allowlist_stopwords_str,
		)
		.unwrap();

		generated_rules += 1;
	}

	writeln!(file, "];").unwrap();

	println!(
		"cargo:warning=gitleaks rules: {} total, {} generated, {} skipped",
		total_rules, generated_rules, skipped_rules
	);
}
